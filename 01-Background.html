<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="./assets/css/style.css">
</head>

<body>

    <body>
        <header>
            <a href="#" class="logo">CS1102 Group Project</a>
            <nav>
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="01-Background.html" class="active">01-Background</a></li>
                    <li><a href="02-Architecture.html">02-Architecture</a></li>
                    <li><a href="03-Pros & Cons.html">03-Pros & Cons</a></li>
                    <li><a href="04-Our Discovery.html">04-Our Discovery</a></li>
                </ul>
            </nav>

        </header>

        <section class="container">
            <h1 class="SectionHeader">Background Information of LLMs</h1>
            <img src="assets\img\LLM.jpg" alt="">
            <main>
                <section class="intro">
                    <h2>History LLMs</h2>
                    <ul>
                        <li>1960s, according to David (2023), the worldâ€™s first chatbot Eliza was created by Joseph Weizenbaum,
                            which gave the foundation and guidance of natural language processing for the future production of more complex LLMs. </li>
                        <li>1997, Long Short-Term Memory (LSTM) networks came into existence.</li>
                        <li>When LLMs first emerged, they were created using RNN models with LSTMs and GRUs.</li>
                    </ul>
                    <a href=''https://www.researchgate.net/publication/378289524_A_Review_on_Large_Language_Models_Architectures_Applications_Taxonomies_Open_Issues_and_Challenges''>
                       

                    <h2> major technological breakthroughs</h2>
                
                        <p> Transformers' scalability has led to breakthroughs in language models. 
                            LLMs contain upwards of 100B parameters.Apart from the scaling, LLMs can generate the text quickly and 
                            the use of LLMs were seen to be enabling human creativity and productivity in language and art like never before. (David, 2023)
                            </p>
                        <p> Besides, LLMs were improved by using different DNN models.Because of this , we got the pre-trained GPT with 12 transformer blocks.
                            In GPT2, it included four pre- trained GPT model and the largest one contain a d(model) value of 1600 , 48 blocks and 1.5 billion model parameters.
                            (Raiaan,2024) LLMs also contained a vocabulary size of 8,000 tokens.</p>

                        <h2>broad application areas of LLMs</h2>
                <p>LLMs are widely used in human life, the most common applications are in education, industry, and some training.
                    According to Moore et al.(2022) ,LLMs that make use of produced Natural language processing (NLP) has significantly advanced thanks to pre-trained transformers (GPT), 
                    which have also sparked the creation of numerous language-based applications. 
                    For example, the City University of Hong Kong provided chatgpt-4 to students to give instant feedback on the educational content and 
                    some companies use the robot in LLMs to automatically reply the repeated and simple messages. As LLMs have excellent problem-solving skills, contextual awareness,
                    advanced language comprehension, and human-like text production capabilities, it is popular in many areas.
</p>
                    
                </section>
            </main>


        </section>
    </body>

</html>
